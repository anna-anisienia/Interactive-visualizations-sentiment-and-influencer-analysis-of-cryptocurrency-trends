---
title: "Analytics Lab Project with Disruptive Elements GmbH: Network Twitter Analysis in R"
author: "Anna Anisienia"
date: "30 June 2018"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    theme: cosmo
    highlight: tango
  pdf_document:
    keep_tex: yes
    number_sections: yes
---

## Google Trends: How often people google Bitcoin and Ethereum?

In the plot below (*and by sorting the table by hits in descending order*), we can see that the number of hits in Google Trends reached a peak during and after the Bitcoin Crash in June 2018.
```{r echo=FALSE, warning=FALSE, message=FALSE}
library(gtrendsR)
library(ggplot2)
library(dplyr)
library(lubridate)
library(DT)
Sys.setenv(TZ="Europe/Berlin") # to be sure: time series analysis
KEYWORDS <- c("Bitcoin", "Ethereum")
gTrendsData <- gtrends(keyword = KEYWORDS, time = paste("2018-06-01", Sys.Date()), geo = "DE") # BTC crash 8-10.06.2018
datTS <- gTrendsData$interest_over_time[, c("date", "hits", "keyword")]
# Create variables for weekdays and weekends
datTS$weekday <- lubridate::wday(datTS$date, label = TRUE, week_start = 1)
datTS$weekend <- datTS$weekday %in% c("Sat", "Sun")
datatable(datTS, filter = list(position = 'top', clear = TRUE),
  options = list(search = list(caseInsensitive = TRUE), pageLength = 5))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
ggplot(datTS, aes(x = date, y = hits, color = weekend)) + 
    geom_line(linetype = 3) + ## 0 = blank, 1 = solid, 2 = dashed, 3 = dotted, # 4 = dotdash, 5 = longdash, 6 = twodash; default SOLID
    geom_point(size = 2) +
    facet_grid(keyword ~ .) +
    labs(x = "Date", y = "Search intensity")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
library("RPostgreSQL")
drv <- dbDriver("PostgreSQL")
con <- dbConnect(drv, dbname = "disruptive",
                host = "zeno.lehre.hwr-berlin.de", port = 5432,
                user = "consultant", password = "pgHWR2018")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
twitter <- dbGetQuery(con, "select distinct text, tweet_created, influencer, influencer_quoted, user_name, retweeter_requoter  from twitter3 
where text ~* '(btc|#eth|ether|bitcoin|ethereum)'
AND (influencer != 'not retweeted post' OR influencer_quoted != 'not quoted post')
order by tweet_created desc LIMIT 2000")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(igraph)
library(visNetwork)
library(dplyr)
```

## Graph 
We want to obtain only the last 1000 tweets. Also, we need to make sure that we get only tweets that either has been retweeted or requoted in order to identify the influencers in the network.

**Assign user IDs and influencer IDs:** The graph analysis requires a very specific format:
- The data needs to be separated into tables `Ties` and `Nodes`
- The `nodes` should contain `id` as the first column and additional attributes such as `name` in the subsequent columns.
- The `ties` represents the edges in a graph, that is why it requires a `weight` argument.

```{r echo=FALSE, warning=FALSE, message=FALSE}
user_df = twitter %>% distinct(user_name)
user_df = user_df %>% mutate(user_id = 1:nrow(user_df))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
influencer_df = twitter %>% distinct(influencer_quoted) %>% filter(influencer_quoted != "not quoted post")
colnames(influencer_df) = "influencer"
influencer_df2 = twitter %>% distinct(influencer) %>% filter(influencer != "not retweeted post")
influencer_df = influencer_df %>% bind_rows(influencer_df2)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
influencer_df = influencer_df %>% mutate(influencer_id = 
                                   seq(from = (1+nrow(user_df)), to = (nrow(influencer_df)+nrow(user_df)), by = 1)
                                   )
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
influencer_as_users = influencer_df
colnames(influencer_as_users) = c("user_name", "user_id")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
nodes = bind_rows(user_df, influencer_as_users)
colnames(nodes) = c("name", "id")
nodes = nodes[, c("id", "name")]
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
final_influencer_df = twitter %>% inner_join(user_df, by = "user_name") %>% inner_join(influencer_df, by = "influencer")
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
ties = final_influencer_df %>% 
          filter(influencer != retweeter_requoter) %>% # avoid to consider self-retweeting posts as influencers
          filter(!is.na(influencer), !is.na(retweeter_requoter)) %>% # both must be not null
          select(from = influencer_id, to = user_id) %>%
          group_by(from, to) %>% count() %>% rename(weight = n) %>% # rename n as weight of the connection bw. from and to
          arrange(-weight)
```

We have some **duplicated user_names**, because some users were also influencers. We removed them by keeping only first of duplicated rows.

```{r echo=FALSE, warning=FALSE, message=FALSE}
nodes = nodes %>% distinct(name, .keep_all = TRUE) # .keep_all to keep user_id as well
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
ties = ties %>% semi_join(nodes, by = c("from" = "id"))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
ties = ties %>% semi_join(nodes, by = c("to" = "id"))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
ties = na.omit(ties)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# ties %>% anti_join(nodes, by = c("from" = "id"))
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
# ties %>% anti_join(nodes, by = c("to" = "id"))
```

Now, we can finally draw the graph and analyze the data interactively.


```{r echo=FALSE, warning=FALSE, message=FALSE}
g <- graph_from_data_frame(ties, directed = TRUE, vertices = nodes)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(visNetwork)
data <- toVisNetworkData(g) # convert igraph to visNetwork
# print head of nodes and edges (another word for ties)
```

```{r echo=FALSE}
top_influencers = data$edges %>% group_by(from) %>% count() %>% arrange(-n)
top_influencers$from[1:20]
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
visNetwork(nodes = data$nodes, edges = data$edges, width = 900, height = 550) %>%
  visPhysics(stabilization = FALSE) %>% 
  visOptions(nodesIdSelection = TRUE, highlightNearest = TRUE) %>%
  visEdges(smooth = FALSE)
```

## Can we find some interesting patterns in the user's behavior?
- it turns out that many `influencers` are only considered as such due to free giveaways and alleged "airdrops" of free cryptocurrency.
```{r echo=FALSE, warning=FALSE, message=FALSE}
DT::datatable(twitter, filter = list(position = 'top', clear = TRUE),
  options = list(search = list(caseInsensitive = TRUE, regex = TRUE), pageLength = 5))
```

## Which of the influencers are the most trending on Google and when?
- Did people seek advice from influencers after Bitcoin crash? 
- it's difficult to assess given that some followers don't necessarily have to google for the influencers, as they already follow them on Twitter.

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(DT)
keywords_top_influencers = top_influencers$from[1:5]
gTrendsData_top5 <- gtrends(keyword = keywords_top_influencers, time = paste("2018-06-01", Sys.Date()))
top5 <- gTrendsData_top5$interest_over_time[, c("date", "hits", "keyword")]
#DT::datatable(top5)
Sys.sleep(120)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
keywords_top_influencers2 = top_influencers$from[6:10]
gTrendsData_top6_10 <- gtrends(keyword = keywords_top_influencers2, time = paste("2018-06-01", Sys.Date()))
top6_10 <- gTrendsData_top6_10$interest_over_time[, c("date", "hits", "keyword")]
# merge two DF together
#top10 = rbind(top5, top6_10)
#DT::datatable(top10)
Sys.sleep(120)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
keywords_top_influencers3 = top_influencers$from[11:15]
gTrendsData_top11_15 <- gtrends(keyword = keywords_top_influencers3, time = paste("2018-06-01", Sys.Date()))
top11_15 <- gTrendsData_top11_15$interest_over_time[, c("date", "hits", "keyword")]
# merge two DF together
#top15 = rbind(top5, top6_10, top11_15)
#DT::datatable(top15)
Sys.sleep(120)
```

```{r echo=FALSE, warning=FALSE, message=FALSE}
keywords_top_influencers4 = top_influencers$from[16:20]
gTrendsData_top16_20 <- gtrends(keyword = keywords_top_influencers4, time = paste("2018-06-01", Sys.Date()))
top16_20 <- gTrendsData_top16_20$interest_over_time[, c("date", "hits", "keyword")]
# merge DF together
top20 = rbind(top5, top6_10, top11_15, top16_20)
DT::datatable(top20, filter = list(position = 'top', clear = TRUE),
  options = list(search = list(caseInsensitive = TRUE, regex = TRUE), pageLength = 5))
```


